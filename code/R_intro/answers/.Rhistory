library(tidyverse)
library(rio)
library(janitor)
MediaBucks <- rio::import("https://docs.google.com/spreadsheets/d/1y2w31HHwE31N9pJoIB1W8oWgW7citB4hzjo99XfwVqo/edit#gid=357643135", sheet = "RealMediaSalaries2")
Reporters <- subset(MediaBucks, grepl("?reporter", TITLE))
summary(Reporters$Salary)
#1: Who is making $230,504 as a reporter???
Reporters %>%
filter(Salary ==230504)
#Make a table for editors, figure out medians.
Editors <- subset(MediaBucks, grepl("?reporter", TITLE))
median(Editors$Salary)
#Make a table for editors, figure out medians.
Editors <- subset(MediaBucks, grepl("?editor", TITLE))
median(Editors$Salary)
#Find highest paid editor. Resent them.
summary(Editors$Salary)
View(Editors)
View(MediaBucks)
Editors <- subset(MediaBucks, grepl("?editor", TITLE, ignore.case = TRUE))
median(Editors$Salary)
#Make a table for editors, figure out medians.
Editors <- subset(MediaBucks, grepl("?editor", TITLE, ignore.case = TRUE))
median(Editors$Salary, na.rm= TRUE)
#Median salary for editors: $60,240
summary(Editors$Salary, na.rm= TRUE)
#Find highest paid editor. Resent them.
summary(Editors$Salary)
#top editor salary: $770,000
Editors %>%
filter(Salary ==770000)
#Make a table for any position involving data
data <- subset(MediaBucks, grepl("?data", TITLE, ignore.case = TRUE))
summary(data$Salary, na.rm= TRUE)
View(data)
#Make a table for any position involving data
data <- subset(MediaBucks, grepl("?data", JOB_DUTIES, ignore.case = TRUE))
summary(data$Salary, na.rm= TRUE)
#Median salary, $50,000
View(data)
Biz <- subset(MediaBucks, grepl("?Business", COMPANY))
summary(Biz$Salary)
Bloom <- subset(MediaBucks, grepl("?Bloomberg", COMPANY))
summary(Bloom$Salary)
colnames(MediaBucks)
#1: Build a table for NewYorkTimes employees
NYT_Emp<- subset(MediaBucks, COMPANY=="NewYorkTimes" | COMPANY=="NYT")
View(NYT_Emp)
#OR, bonus
NYT2 <- subset(MediaBucks, COMPANY=="NewYorkTimes" | COMPANY=="NYT")
#2: Determine median salary of NewYorkTimes employees
summary(NYT$Salary)
#1: Build a table for NewYorkTimes employees
NYT <- subset(MediaBucks, COMPANY=="NewYorkTimes")
#OR, bonus
#NYT2 <- subset(MediaBucks, COMPANY=="NewYorkTimes" | COMPANY=="NYT")
#2: Determine median salary of NewYorkTimes employees
summary(NYT$Salary)
summary(NYT2$Salary)
NYTmax <- max(NYT_Emp$Salary)
highest_paidNYT <- NYT_Emp %>%
filter(Salary == 65000) %>%
select(Salary, Gender, Race, TITLE)
View(highest_paidNYT)
SF <- rio::import("https://docs.google.com/spreadsheets/d/1-nkosLJKkfeLSl-UG82DDyiEw5-62kX2alS6ICG9iuk/edit#gid=552005485", sheet = "SF Police_Department_Calls_for_")
View(SF)
Days <- SF %>%
count(call_date) %>%
arrange(desc(n))
names(SF)
#This cleans column names
SF <- janitor::clean_names(SF)
#This processes dates for analysis
SF$call_date2 <- mdy(SF$call_date)
#This creates a new column for year
SF$year <- year(SF$call_date2)
Days <- SF %>%
count(call_date2) %>%
arrange(desc(n))
head(Days)
SF_call_dates <- SF %>%
count(call_date) %>%
group_by(call_date) %>%
ggplot(aes(x = call_date, y = n,
fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
#This is your title sequence
labs(title = "311 Calls for Service By Day, San Francisco",
subtitle = "SF PD Service Call Data, 2016-2019",
caption = "Graphic by Marilyn Harbert, 09-04-2024",
y="Number of Calls",
x="Date")
plot(SF_call_dates)
SF_call_dates <- SF %>%
count(call_date) %>%
#group_by(call_date) %>%
ggplot(aes(x = call_date, y = n,
fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
#This is your title sequence
labs(title = "311 Calls for Service By Day, San Francisco",
subtitle = "SF PD Service Call Data, 2016-2019",
caption = "Graphic by Marilyn Harbert, 09-04-2024",
y="Number of Calls",
x="Date")
plot(SF_call_dates)
SF %>%
count(call_date2) %>%
#Sandwich it onto a simple ggplot
ggplot(aes(x = call_date2, y = n, fill = n)) +
geom_bar(stat = "identity") +
labs(title = "311 Calls for Service By Day, San Francisco",
subtitle = "SF PD Service Call Data, 2016-2019",
caption = "Graphic by Wells",
y="Number of Calls",
x="Day")
daily_calls <- SF %>%
group_by(call_date) %>%
summarise(total_calls = n()) %>%
arrange(desc(total_calls))
View(daily_calls)
Days <- SF %>%
count(call_date2) %>%
arrange(desc(n))
View(Days)
daily_calls <- SF %>%
group_by(call_date) %>%
summarise(total_calls = n()) %>%
arrange(desc(total_calls))
#RSW comment - A little easier way to do the same thing
# Days <- SF %>%
#   count(call_date2) %>%
#   arrange(desc(n))
ggplot(data=daily_calls) +
geom_col(mapping=aes(x=daily_calls, y=n))
NYT %>%
filter(Salary == 350000)
MediaBucks %>% select(COMPANY) %>%
filter(MediaBucks$Salary == max(max(Business$Salary),max(Bloomberg$Salary)) )
Business <- subset(MediaBucks, grepl("?Business?", COMPANY))
summary(Business$Salary)
Bloomberg <- subset(MediaBucks, grepl("?Bloomberg?", COMPANY))
summary(Bloomberg$Salary)
#Which one is higher?
MediaBucks %>% select(COMPANY) %>%
filter(MediaBucks$Salary == max(max(Business$Salary),max(Bloomberg$Salary)) )
MediaBucks %>% select(COMPANY) %>%
filter(MediaBucks$Salary == max(max(Business$Salary),max(Bloomberg$Salary)) )
Editors %>% filter(Salary == max(Editors$Salary))
Editors <-
subset(Reporters, grepl("?Editor?", TITLE))
median(Editors$Salary)
#RSW comment: this eliminates case sensitivity, captures a wider number of people
# Editors <- subset(MediaBucks, grepl("?editor", TITLE, ignore.case = TRUE))
# summary(Editors$Salary, na.rm= TRUE)
Editors %>% filter(Salary == max(Editors$Salary))
CallsInDay <- SF %>%
count(call_date) %>%
arrange(desc(n))
ggplot(CallsInDay, aes(x=call_date, y=n)) +
geom_col(position="dodge") +
labs(title = "311 Calls for Service By Day, San Francisco",
subtitle = "SF PD Service Call Data, 2016-2019",
caption = "Graphic by Bridget Lang, 9-5-2024",
y="Number of Calls",
x="Day")
#ggplot(data=CallsInDay) +
#  geom_col(mapping=aes(x=CallsInDay$`Call Date`, y=n, fill=n))
filter(NYT$Salary == 350000)
NYT %>%
filter(Salary == 350000)
ggplot(Day, aes(x = call_date2, y = n, fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
labs(title = "311 Calls for Service By Day, San Francisco",
subtitle = "SF PD Service Call Data, 2016-2019",
caption = "Graphic by Xingman Wu, 9-7-2024",
y = "Number of Calls",
x = "Day")
Day <- SF %>%
count(call_date2) %>%
group_by(call_date2) %>%
arrange(desc(n))
head(Day)
# 2019-08-15 had the most 311 calls
ggplot(Day, aes(x = call_date2, y = n, fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
labs(title = "311 Calls for Service By Day, San Francisco",
subtitle = "SF PD Service Call Data, 2016-2019",
caption = "Graphic by Xingman Wu, 9-7-2024",
y = "Number of Calls",
x = "Day")
head(Days %>%
group_by(call_date2) %>%
filter(n == max(n)),5)
head (Days %>%
group_by(call_date2) %>%
arrange(n) %>%
filter(n == max(n)),5)
Editors <- subset(MediaBucks, grepl("?editor", TITLE, ignore.case = TRUE))
summary(Editors$Salary, na.rm= TRUE)
View(data)
#load tidyverse, tidytext, rio and quanteda libraries
library(tidyverse)
library(rio)
library(tidytext)
library(quanteda)
#Import dataframe
lynch <- read_csv("../data/articles_oct_19.csv")
lynch1910 <-  lynch %>%
filter(year >= 1900 & year <= 1910)
#load tidyverse, tidytext, rio and quanteda libraries
library(tidyverse)
library(rio)
library(tidytext)
library(quanteda)
lynch <- read_csv("/Users/robwells/Code/CompText_Jour/data/articles_oct_19.csv")
lynch1910 <-  lynch %>%
filter(year >= 1900 & year <= 1910)
lynch1910 %>%
select(filename) %>%
distinct(filename, .keep_all = TRUE) %>%
count(filename) %>%
summarize(total =sum(n))
#There are 1,732 distinct articles in the dataset for the 1900-1910
states1900 <- lynch1910 %>%
select(newspaper_state, filename) %>%
distinct(filename, .keep_all = TRUE) %>%
count(newspaper_state) %>%
arrange(desc(n))
#and now provide code to list the top five states
states1900 %>%
select(newspaper_state, n) %>%
slice_max(n, n=10)
# 1 Wisconsin          91
# 2 Arkansas           90
# 3 Mississippi        89
# 4 Nebraska           83
# 5 Utah               80
stories <- str_replace_all(lynch1910$sentence, "- ", "")
stories_df <- tibble(stories,)
# unnest includes lower, punct removal
stories_tokenized <- stories_df %>%
unnest_tokens(word,stories)
stories_tokenized
data(stop_words)
test <- stop_words %>%
as.data.frame()
head(test)
stories_tokenized <- stories_tokenized %>%
anti_join(stop_words, by = c("word" = "word")) %>%
filter(word != "temp_file") %>%
filter(word != "stories_corpus") %>%
filter(!grepl('[0-9]', word))
# Word Count
story_word_ct <- stories_tokenized %>%
count(word, sort=TRUE)
head(story_word_ct)
#write_csv(lynch_word_ct, "lynching_corpus_word_count.csv")
stories_bigrams <- stories_df %>%
unnest_tokens(bigram, stories, token="ngrams", n=2)
stories_bigrams_separated <- stories_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
stories_bigram_cts <- stories_bigrams_separated %>%
count(word1, word2, sort = TRUE)
stories_bigram_cts
stories_bigrams_filtered <- stories_bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
stories_bigram_cts2 <- stories_bigrams_filtered %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
stories_bigram_cts2
#replace Date for the decade analyzed
stories_bigram_cts_1900 <- stories_bigram_cts %>%
mutate(decade = "1900s")
#write_csv(stories_bigram_cts_post1940, "../output/post1940_lynch_bigram_count.csv")
bp <- lynch %>%
filter(black_press=="Y")
stories <- str_replace_all(bp$sentence, "- ", "")
stories_df <- tibble(stories,)
# unnest includes lower, punct removal
stories_tokenized <- stories_df %>%
unnest_tokens(word,stories)
stories_tokenized
bp_stories_bigrams <- stories_df %>%
unnest_tokens(bigram, stories, token="ngrams", n=2)
bp_stories_bigrams <- stories_df %>%
unnest_tokens(bigram, stories, token="ngrams", n=2)
bp_stories_bigrams_separated <- bp_stories_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
bp_stories_bigrams_separated
wp <- lynch %>%
filter(!black_press=="Y")
View(wp)
wp <- lynch %>%
filter(black_press==is.na)
View(lynch)
wp <- lynch %>%
filter(black_press=is.na)
wp <- lynch %>%
filter(black_press=="is.na")
wp <- lynch %>%
filter(!black_press=="Y")
wp <- lynch %>%
filter(black_press !="Y")
wp <- lynch %>%
filter(is.na(black_press))
View(wp)
wp <- lynch %>%
filter(black_press=="")
wp <- lynch %>%
filter(black_press==" ")
wp <- lynch %>%
filter(!black_press=="Y")
wp <- lynch %>%
filter(black_press != "Y")
head(lynch)
wp <- lynch %>%
filter(black_press != "Y ")
table(lynch$black_press)
stories <- str_replace_all(wp$sentence, "- ", "")
stories_df <- tibble(stories,)
# unnest includes lower, punct removal
stories_tokenized <- stories_df %>%
unnest_tokens(word,stories)
stories_tokenized
wp_stories_bigrams <- stories_df %>%
unnest_tokens(bigram, stories, token="ngrams", n=2)
wp_stories_bigrams_separated <- wp_stories_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
wp_stories_bigrams_separated
wp <- lynch %>%
filter(is.na(black_press))
#for some reason, the column had a trailing space so the anti-filter only worked like so:
# wp <- lynch %>%
#   filter(black_press != "Y ")
#to eliminate leading and trailing spaces
# lynch <- lynch %>%
#   mutate(black_press = trimws(black_press))
stories <- str_replace_all(wp$sentence, "- ", "")
stories_df <- tibble(stories,)
# unnest includes lower, punct removal
stories_tokenized <- stories_df %>%
unnest_tokens(word,stories)
stories_tokenized
wp_stories_bigrams <- stories_df %>%
unnest_tokens(bigram, stories, token="ngrams", n=2)
wp_stories_bigrams_separated <- wp_stories_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
wp_stories_bigrams_separated
print(paste0("The top five Black press bigrams were: ",
paste(head(wp_stories_bigrams_separated))
print(paste0("The top five Black press bigrams were: ",
print(paste0("The top five Black press bigrams were: ",         paste(head(wp_stories_bigrams_separated))))
print(paste0("The top five Black press bigrams were: ",         paste(head(wp_stories_bigrams_separated, collapse = ", "))))
head(bp_stories_bigrams_separated)
print("The top five Black press bigrams were:")
# Display the top 5 bigrams
print(head(wp_stories_bigrams_separated, 5))
print("The top five Black press bigrams were:")
wp_stories_bigrams_separated %>%
head(5) %>%
kable()
print("The top five Black press bigrams were:")
wp_stories_bigrams_separated %>%
head(5) %>%
kable::kable()
print("The top five Black press bigrams were:")
wp_stories_bigrams_separated %>%
head(5) %>%
knitr::kable()
print("The top five Black press bigrams were:")
wp_stories_bigrams_separated %>%
head(5) %>%
kable()
library(knitr)
print("The top five Black press bigrams were:")
wp_stories_bigrams_separated %>%
head(5) %>%
kable()
wp_stories_bigrams_separated %>%
head(5) %>%
kable()
print("The top five Black press bigrams were:")
print(head(wp_stories_bigrams_separated, 5))
paste(head(wp_stories_bigrams_separated, collapse = ", "))))
print(paste0("The top five Black press bigrams were: ",
print(head(wp_stories_bigrams_separated, 5))
print(paste0("The top five Black press bigrams were: "))
print("The top five Black press bigrams were: ")
print(head(wp_stories_bigrams_separated, 5))
cat("The top five Black press bigrams were:\n")
head(bp_stories_bigrams_separated, 5)
# Print out summary sentence
cat("The top five Black press bigrams were:\n")
head(bp_stories_bigrams_separated, 5)
cat("The top five Black press bigrams were:\n")
wp_stories_bigrams_separated %>%
head(5) %>%
kable()
# Print out summary sentence
cat("The top five Black press bigrams were:\n")
head(bp_stories_bigrams_separated, 5)
output <- paste("The top five Black press bigrams were:")
# Print the sentence and then use kable to display the table
output
head(wp_stories_bigrams_separated, 5) %>%
kable()
install.packages("knitr")
#load tidyverse, tidytext, rio and quanteda libraries
library(tidyverse)
library(rio)
library(tidytext)
library(quanteda)
library(knitr)
output <- paste("The top five Black press bigrams were:")
# Print the sentence and then use kable to display the table
output
head(wp_stories_bigrams_separated, 5) %>%
kable()
